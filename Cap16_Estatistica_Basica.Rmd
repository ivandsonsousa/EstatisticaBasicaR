---
title: 'Estatística Básica: Capítulo 16'
author: "Ivandson Praeiro de Sousa"
date: "2022-08-14"
output:
  html_document:
    number_sections: no
    toc: yes
    toc_float: yes
    theme: cerulean
    # highlight: spacelab
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introdução

Neste capítulo[^bussab_morettin], estudamos modelos de regressão linear. Conforme descrito no texto, a regressão linear simples é um modelo para estimação da média condicional $E(Y|x) = \mu(x)$ a partir dos valores observados numa amostra de tamanho $n$, $(x_i, y_i)$. Nesse caso, a relação entre as variáveis $x$ e $Y$ pode ser modelada por

$$ y_i = E(Y|x_i) + e_i = \mu(x_i) + e_i, $$

ou seja, dizemos que o que observamos flutua em torno da média de maneira aleatória e, para podermos estimar e fazer inferências acerca dos parâmetros do modelo, fazemos algumas suposições pertinetes à respeito do comportamento dos resíduos $e_i$.

> A inclusão do fator aleatório aqui (erro ou resíduos) reflete o fato de desconhecermos outros fatores que porventura influenciam a variável $Y$. Queremos modelar o comportamento de $Y$ com $X$ e, para isso, modelamos toda a variação em $Y$ não devida a $X$ por meio dos resíduos $e_i$.

Também vimos que o termo amplo **linear**, usado independentemente da forma gráfica do modelo a ser ajustado, advêm do fato de que o modelo é linear nos parâmetros. De fato, o modelo de regressão linear nos permite obter desde os parâmetros do modelo linear (linha reta) até os parâmetros de modelos não lineares como o polinomial ou exponencial.

Vimos ainda que o modelo de regressão linear a ser postulado para um dado fenômeno observado por meio de uma amostra depende do conhecimento que temos daquele fenômeno. Nesse sentido, o palpite sobre o modelo pode ser melhor embasado com o auxílio de um diagrama de dispersão.

Para o desenvolvimento dos exemplos e dos problemas deste capítulo, iremos utilizar as funções `lm()`, para obter as estimativas dos parâmetros de um modelo de regressão linear passado como argumento da função, `conf.int()`, para obter os intervalos de confiança para os parâmetros do modelo, e a função `predict()`, para obter o intervalo de predição para uma futura observação da variável resposta dada pelo nosso modelo postulado.


## Carregamento dos pacotes necessários

```{r, message=FALSE}
library(dplyr)
library(ggplot2)
library(readxl)
library(combinat)
library(kableExtra)
```


# Exemplos e problemas do livro

## Exemplo 16.1

```{r}
dados = read_excel("exemplo-15.1.xlsx")
```

Aqui, vamos ajustar um modelo linear, com $y$ sendo o tempo de reação ao estímulo e $x$ sendo a idade do indivíduo.


```{r}
x = dados$X
y = dados$Y
n = nrow(dados)
```

O estimador para a média condicional obtido a partir do nosso modelo terá a forma

$$ \hat{y_i} = \hat{\alpha} + \hat{\beta}x_i, $$

com 

$$ \hat{\alpha} = \bar{y} - \hat{\beta}\bar{x}$$

$$ \hat{\beta} = \dfrac{\Sigma_{i = 1}^n x_iy_i - n\bar{x}\bar{y}}{\Sigma_{i = 1}^n x_i^2 - n\bar{x}^2} $$

Primeiro, vamos estimar os parâmetros $\alpha$ e $\beta$ do modelo "manualmente". Depois, faremos com o auxílio da função `lm()` do R.


```{r}
beta_hat = (sum(x*y) - n*mean(x)*mean(y))/(sum(x^2) - n*mean(x)^2)
alpha_hat = mean(y) - beta_hat*mean(x)

alpha_hat
beta_hat
```
Logo, nosso modelo ajustado pode ser escrito como

$$ \hat{y}_i = 80.5 + 0.90x_i $$

Podemos também obter os estimadores para os coeficientes através da função `lm()`:


```{r}
lm(formula = Y ~ X, dados) %>% 
  summary()
```

> Um ponto que merece observação aqui é a forma da equação obtida (estimada) para a reta de regressão. Percebemos que nela não entra o termo de erro (resíduos). Isso ocorre porque um dos pressupostos dos modelos de regressão linear é que os resíduos têm esperança igual a zero e variância constante. Então, se estamos usando estimadores não viesados, eles "acertam" o valor do parâmetro. Dessa forma, a esperança do estimador para os resíduos deve ser igual a zero.


## Problema 1

(a) Vamos usar a função `lm()` para encontrar a reta de mínimos quadrados para $z$ (acuidade visual) em função de $x$ (idade):

```{r}
modelo = lm(formula = Z ~ X, dados)
modelo$coefficients
```

Perceba que, desta vez, decidimos não usar a função `summary()` para exibir o resultado da aplicação do modelo, uma vez que agora apenas estamos interessados nos estimadores do parâmetros do modelo.

Podemos então escrever a reta de mínimos quadrados como sendo:

$$ \hat{y}_i = 101,50 - 0,55x_i. $$

(b) Nesse caso, o parâmetro $\alpha$ significa a acuidade visual que a pessoa já tem ao nascer. O parâmetro $\beta$ significa a variação que o indivíduo comum sofre em sua acuidade visual para cada ano que se passa. Como ele é negativo aqui, isso significa que a pessoa perde sensibilidade visual a cada ano.

(c) Aqui também podemos usar a saída da função `lm()` para olhar para os resíduos do modelo. Vamos colocá-los lado a lado com os valores das variáveis de interesse:


```{r}
kable(data.frame(individuo = dados$indivíduo, X = dados$X, Z = dados$Z, e = modelo$residuals)) %>%
  kable_styling(
    full_width = F,
    bootstrap_options = c("striped", "hover", "condensed", "responsive")
  )
```
Como podemos ver, o desvio mais alto ocorre para o indivíduo nº 19, cujo módulo é igual a 19,5.


## Problema 2

(a) Primeiro, vamos admitir os dados do problema:


```{r}
dados = data.frame(
  x = c(10, 13, 5, 7, 20),
  y = c(4, 3, 6, 5, 2)
)
```

Agora, vamos obter os estimadores:

```{r}
modelo = lm(formula = y ~ x, dados)
modelo$coefficients
```

Logo, a reta de mínimos quadrados para este modelo será escrita como

$$ \hat{y}_i = 6,87 - 0,26x_i. $$

(b) Vamos usar a biblioteca `ggplot2` para fazer o gráfico pedido:


```{r}
ggplot(aes(x, y), data = dados) +
  geom_point(size = 2, color = "red") +
  stat_smooth(formula = y ~ x, method = "lm", size = 1.2) + 
  labs(
    title = "gráfico de dispersão e reta ajustada",
    subtitle = "modelo linear para aluguel versus idade"
  ) + 
  theme(text = element_text(size = 16))
```

Como vemos, apesar do reduzido número de pontos, o modelo ajustado parece apropriado.


(c) Nesse caso, o coeficiente angular nos diz que o valor médio do aluguel diminui 0,26 unidades a cada aumento de um ano na idade da casa.

(d) O coeficiente linear nesse caso nos diz que o valor médio do aluguel de casas novas é igual a 6,87 unidades.


## Problema 3

(a) Vamos primeiro escrever os dados do problema, observando que existem repetições:


```{r}
dados = data.frame(
  Pot = c(38, 43, 32, 26, 33, 19, 27, 23, 14, 21),
  Temp = c(30, 30, 50, 50, 50, 70, 70, 70, 90, 90)
)
```


(b) Agora, o gráfico de dispersão, já com a reta ajustada:


```{r}
ggplot(aes(x = Temp, y = Pot), data = dados) + 
  geom_point(size = 2, col = "black") + 
  geom_smooth(formula = y ~ x, size = 1.2, col = "orange", method = "lm") +
  labs(
    title = "Gráfico de dispersão para potência versus temperatura",
    x = "Temperatura",
    y = "Potência"
  ) + 
  theme(text = element_text(size = 16))
```

(c) Apesar dos dois pontos com resíduos maiores que os demais, percebemos que os pontos realmente se ajustam razoavelmente bem a uma linha reta.


(d) Para responder a essa pergunta, vamos primeiro obter a reta de regressão linear para potência versus temperatura:

```{r}
modelo = lm(formula = Pot ~ Temp, data = dados)

modelo$coefficients
```

Assim, podemos escrever o nosso modelo como:

$$ \hat{y}_i = 50,457 - 0,381x_i $$
Assim, vemos que a potência média será igual a zero quando a temperatura for igual a `r -modelo$coefficients[1]/modelo$coefficients[2]`.


## Problema 4

Vamos retomar os dados do exemplo 15.1:

```{r}
dados = read_excel("exemplo-15.1.xlsx")
```

Nesse caso, queremos investigar a reta de regressão para a variável $Y$ como função de $Z$:

```{r}
ggplot(aes(Z, Y), data = dados) +
  geom_point(size = 2, color = "red") +
  stat_smooth(formula = y ~ x, method = "lm", size = 1.2) + 
  labs(
    title = "gráfico de dispersão e reta ajustada",
    subtitle = "modelo linear para tempo de reação versus acuidade visual"
  ) + 
  theme(text = element_text(size = 16))
```

Vamos obter a reta de regressão:

```{r}
modelo = lm(formula = Y ~ Z, data = dados)

modelo$coefficients
```

$$ \hat{y}_i = 162,079 - 0,642z_i $$

## Problema 5

Primeiro, devemos lembrar que os dados do problema 1 são aqueles do exemplo 15.1:


```{r}
dados = read_excel("exemplo-15.1.xlsx")
```

Agora, vamos aplicar a função `anova()` para obter a tabela ANOVA para o modelo considerado no problema 1, ou seja, um modelo de regressão linear para a variável resposta $Y$ (acuidade visual), tendo como preditora a variável $X$ (idade):


```{r}
tabela = anova(lm(formula = Z ~ X, dados))
tabela
```

(a) Conforme as páginas 469 e 470 do livro-texto, sabemos que:

$$ S^2 = \dfrac{SQTot}{n-1} $$

$$ S_e^2 = \dfrac{SQRes}{n-p}  = \dfrac{SQRes}{n-2}$$
Assim, podemos calculá-los com base na tabela ANOVA acima:


```{r}
n = nrow(dados)
S2 = sum(tabela$`Sum Sq`)/(n-1)
S2
Se2 = tabela$`Sum Sq`[2]/(n-2)
Se2
```


(b) Vemos então que a redução na soma do quadrado dos resíduos não foi grande ao passar do modelo mais simples com um único parâmetro para o nosso modelo de regressão linear.

(c) Ainda com o resultado da tabela ANOVA, podemos obter:


```{r}
rsq = tabela$`Sum Sq`[1]/sum(tabela$`Sum Sq`)
rsq
```

ou seja, em torno de 16%. Essa é a proporção da variabilidade total da acuidade visual que é explicada pela relação linear com a idade.


## Problema 6

Primeiro, vamos admitir os dados do problema em um dataframe:


```{r}
dados = data.frame(
  tempo = c(10.8, 14.4, 19.6, 18, 8.4, 15.2, 11, 13.3, 23.1),
  volume = c(20.39, 24.92, 34.84, 31.72, 13.59, 30.87, 17.84, 23.22, 39.65)
)
```

(a) Para fazer o diagrama de dispersão pedido, utilizaremos o pacote `ggplot2`. Vamos aproveitar para inserir a reta de regressão no mesmo plot:


```{r}
ggplot(aes(x = tempo, y = volume), data = dados) + 
  geom_point(size = 2, color = "red") + 
  stat_smooth(formula = y ~ x, method = "lm", size = 1.2) +
  labs(
    x = "Volume",
    y = "Tempo",
    title = "Diagrama de dispersão",
    subtitle = "Tempo versus Volume"
  ) + 
  theme(text = element_text(size = 16))
```


(b) Para obeter os estimadores dos parâmetros da reta de regressão, utilizaremos novamente a função `lm()`:


```{r}
lm(formula = tempo ~ volume, data = dados)
```
Assim, a reta de regressão pedida tem a forma:

$$ \hat{t_i} = 0,6625 + 0,5393 v_i $$

(c) 

```{r}
tabela = anova(lm(formula = tempo ~ volume, data = dados))
tabela
```


(d) Conforme já visto acima, o valor de $S^2$ se relaciona com a soma dos quadrados totais, enquanto $S_e^2$ se relaciona com a soma dos quadrados dos resíduos:


```{r}
n = nrow(dados)
S2 = sum(tabela$`Sum Sq`)/(n-1)
S2
Se2 = tabela$`Sum Sq`[2]/(n-2)
Se2
```

Como vemos, $S^2 >> S_e^2$. Vamos obter o $R^2$ para o modelo:

```{r}
rsq = tabela$`Sum Sq`[1]/sum(tabela$`Sum Sq`)
rsq
```
Assim, cerca de 96% da variabilidade total do tempo gasto para acondicionar os objetos é explicada pela relação linear com o volume.

(e) Conforme os resultados da tabela ANOVA obtida, vemos que conhecer o volume do pacote ajuda sim a prever o tempo de empacotamento.


## Problema 7

Como estamos o mesmo nome para os conjuntos de dados de cada problema, estamos sobrepondo uns sobre os outros. Dessa forma, precisamos reescrever aqui os dados do problema 2:

```{r}
dados = data.frame(
  x = c(10, 13, 5, 7, 20),
  y = c(4, 3, 6, 5, 2)
)
```

Finalmente, o resultado pedido:

```{r}
tabela = anova(lm(formula = y ~ x, dados))
tabela
```



```{r}
rsq = tabela$`Sum Sq`[1]/sum(tabela$`Sum Sq`)
rsq
```


Como vemos, cerca de 94% da variação no preço dos aluguéis das casas é explicado pela respectiva idade. Indo além, vemos que esse resultado não é mero acaso, já que o p-valor do teste é $p < 0.01$.


## Problema 8

Novamente, vamos admitir os dados do problema 3:


```{r}
dados = data.frame(
  Pot = c(38, 43, 32, 26, 33, 19, 27, 23, 14, 21),
  Temp = c(30, 30, 50, 50, 50, 70, 70, 70, 90, 90)
)
```

Vamos agora obter a tabela ANOVA para o modelo ajustado e o valor de $R^2$:

```{r}
tabela = anova(lm(formula = Pot ~ Temp, dados))
tabela
```


```{r}
rsq = tabela$`Sum Sq`[1]/sum(tabela$`Sum Sq`)
rsq
```

Assim, vemos que cerca de 85% da variação na potência dos antibióticos pode ser explicada pela relação linear com a temperatura na qual eles são acondicionados, com $p < 0.01$, o que indica que esse resultado é significativo. Além disso, podemos olhar para os parâmetros do ajuste:

```{r}
lm(formula = Pot ~ Temp, dados)
```
Logo, vemos que a potência diminui com o aumento da temperatura.


## Problema 9

Vamos receber novamente os dados do problema 4:


```{r}
dados = read_excel("exemplo-15.1.xlsx")
```

Agora, vamos obter a tabela ANOVA para o modelo linear ajustado para explicar a variável $Y$ (tempo de reação ao estímulo visual) como função da acuidade visual $Z$:

```{r}
tabela = anova(lm(formula = Y ~ Z, data = dados))
tabela
```

```{r}
rsq = tabela$`Sum Sq`[1]/sum(tabela$`Sum Sq`)
rsq
```

Como vemos, aproximadamente 57% da variabilidade do tempo de resposta ao estímulo é explicada pela relação linear com a acuidade visual do indivíduo. Além disso, vemos que o resultado é significativo na maioria dos níveis de significância comumente utilizados.



## Problema 10

Primeiro, vamos novamente ler os dados do problema 5:

```{r}
dados = read_excel("exemplo-15.1.xlsx")
```


(a) Vamos obter os intervalos de confiança de 95% para os parâmetros do nosso modelo linear para acuidade visual ($Z$) em função da idade ($x$):


```{r}
lm(formula = Z ~ X, dados) %>%
  confint(parm = 2)
```

(b) E agora, o IC de 90% para o parâmetro $\alpha$:


```{r}
lm(formula = Z ~ X, dados) %>%
  confint(parm = 1, level = 0.90)
```

(c) Vamos obter a tabela ANOVA para o nosso modelo e, a partir do resultado (estatística F), rejeitar ou não a hipótese nula $H_0: \beta = 0$.

```{r}
lm(formula = Z ~ X, dados) %>%
  anova()
```

De acordo com nosso resultado, não podemos rejeitar a hipótese nula no nível de 0,05, já que o p-valor obtido foi de $\approx 0,08$. Deste modo, concluímos que o resultado não é significativo, ou seja, o grau de explicação que o nosso modelo fornece para a variável resposta aparentemente é um mero produto do acaso.


(d) Ainda usando o mesmo conjunto de dados, vamos lembrar de que queremos estimar a acuidade visual média a partir do nosso modelo linear, dado o valor de $x = 28$ e, em seguida, determinar o IC para este resultado:

```{r}
lm(formula = Z ~ X, dados) %>%
  predict(newdata = data.frame(X = 28), interval = "confidence", level = 0.95)
```
O que essa função está fazendo é calcular o valor da variável resposta para $x = 28$ e, em seguida, determinar o intervalo de confiança para a média condicional (resposta), dada pelo nosso modelo.

(e) Na mesma linha, vamos obter agora o intervalo de predição para a acuidade visual (variável resposta) do grupo etário com 28 anos (variável explicativa):

```{r}
lm(formula = Y ~ X, dados) %>%
  predict(newdata = data.frame(X = 28), interval = "predict", level = 0.95)
```
Esse resultado nos diz que, se obtivermos um número grande de amostras de pares $(x, Z)$, todas do mesmo tamanho $n$, cerca de 95% dos intervalos de predição assim construídos conterão o verdadeiro valor da variável resposta, dado aquele valor da variável explicativa $x$.


## Problema 11

Como o conjunto de dados é o mesmo do problema anterior, vamos apenas olhar novamente para a tabela ANOVA construída no problema 9:


```{r}
tabela = anova(lm(formula = Y ~ Z, data = dados))
tabela
```

Vamos também calcular o valor do coeficiente de explicação $R^2$ do nosso modelo:

```{r}
tabela$`Sum Sq`[1]/sum(tabela$`Sum Sq`)
```

Portanto, vemos que cerca de 57% da variabilidade da nossa variável reposta $Y$ é explicada pelo nosso modelo. Ainda, olhando para a estatística F da nossa tabela ANOVA, vemos que o resultado é siginificativo, já que $p < 0,05$. Assim, podemos rejeitar a hipótese nula de que $\beta = 0$ e concluir que a acuidade visual pode explicar o tempo de resposta a um estímulo visual segundo o nosso modelo.


## Problema 12

Para saber se a quantidade de fertilizante de fato nos ajuda a explicar o comportamento da produção de soja, precisamos verificar se o resultado para o nosso parâmetro $\beta$ é significativo. Como nos foi dado o valor da estatística $t$ para cada parâmetro estimado, precisamos apenas ver se ele está dentro ou fora da regisão crítica para rejeição da hipótese nula $H_0: \beta = 0$.


```{r}
cat(
  "Região de aceitação:",
  qt(p = c(0.025, 0.975), df = 20-2)
)
```

Como o valor da estatística $t$ para o parâmetro $\beta$ está dentro da regiçaõ de aceitação (ou fora da região crítica), não podemos rejeitar a hipótese nula de que $\beta = 0$. Em outras palavras, concluímos que o nosso modelo provavelmente não serve para explicar o comportamento da produção de soja como função da quantidade de fertilizante utilizado.

Podemos também olhar para o p-valor, o que irá nos levar à mesma conclusão:

```{r}
pt(1.65, df = 20-2)
```

## Problema 13

## Problema 14

## Problema 15


## Análise de resíduos

- A função `par()` é usada para definir parâmetros de gráficos

- O argumento `mfrow` divide o gráfico conforme uma matriz $n_r \times c_c$, plotando primeiro os quadros horizontais.

- A função `plot()`


```{r}
dados = read_excel("exemplo-15.1.xlsx")
modelo = lm(formula = Y ~ X, dados)
par(mfrow = c(2,2))
plot(modelo, which = c(1:4), pch = 16)
```



[^bussab_morettin]: MORETTIN, Pedro Alberto; BUSSAB, Wilton Oliveira. **Estatística básica**. Saraiva Educação SA, 2017.