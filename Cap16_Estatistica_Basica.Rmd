---
title: 'Estatística Básica: Capítulo 16'
author: "Ivandson Praeiro de Sousa"
date: "2022-08-14"
output:
  html_document:
    number_sections: no
    toc: yes
    toc_float: yes
    theme: cerulean
    # highlight: spacelab
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introdução

Neste capítulo[^bussab_morettin], estudamos modelos de regressão linear. Conforme descrito no texto, a regressão linear simples é um modelo para estimação da média condicional $E(Y|x) = \mu(x)$ a partir dos valores observados numa amostra de tamanho $n$, $(x_i, y_i)$. Nesse caso, a relação entre as variáveis $x$ e $Y$ pode ser modelada por

$$ y_i = E(Y|x_i) + e_i = \mu(x_i) + e_i, $$

ou seja, dizemos que o que observamos flutua em torno da média de maneira aleatória e, para podermos estimar e fazer inferências acerca dos parâmetros do modelo, fazemos algumas suposições pertinetes à respeito do comportamento dos resíduos $e_i$.

> A inclusão do fator aleatório aqui (erro ou resíduos) reflete o fato de desconhecermos outros fatores que porventura influenciam a variável $Y$. Queremos modelar o comportamento de $Y$ com $X$ e, para isso, modelamos toda a variação em $Y$ não devida a $X$ por meio dos resíduos $e_i$.

Também vimos que o termo amplo **linear**, usado independentemente da forma gráfica do modelo a ser ajustado, advêm do fato de que o modelo é linear nos parâmetros. De fato, o modelo de regressão linear nos permite obter desde os parâmetros do modelo linear (linha reta) até os parâmetros de modelos não lineares como o polinomial ou exponencial.

Vimos ainda que o modelo de regressão linear a ser postulado para um dado fenômeno observado por meio de uma amostra depende do conhecimento que temos daquele fenômeno. Nesse sentido, o palpite sobre o modelo pode ser melhor embasado com o auxílio de um diagrama de dispersão.

Para o desenvolvimento dos exemplos e dos problemas deste capítulo, iremos utilizar as funções `lm()`, para obter as estimativas dos parâmetros de um modelo de regressão linear passado como argumento da função, `conf.int()`, para obter os intervalos de confiança para os parâmetros do modelo, e a função `predict()`, para obter o intervalo de predição para uma futura observação da variável resposta dada pelo nosso modelo postulado.


## Carregamento dos pacotes necessários

```{r, message=FALSE}
library(dplyr)
library(ggplot2)
library(readxl)
library(combinat)
library(kableExtra)
```


# Exemplos e problemas do livro

## Exemplo 16.1

```{r}
dados = read_excel("exemplo-15.1.xlsx")
```

Aqui, vamos ajustar um modelo linear, com $y$ sendo o tempo de reação ao estímulo e $x$ sendo a idade do indivíduo.


```{r}
x = dados$X
y = dados$Y
n = nrow(dados)
```

O estimador para a média condicional obtido a partir do nosso modelo terá a forma

$$ \hat{y_i} = \hat{\alpha} + \hat{\beta}x_i, $$

com 

$$ \hat{\alpha} = \bar{y} - \hat{\beta}\bar{x}$$

$$ \hat{\beta} = \dfrac{\Sigma_{i = 1}^n x_iy_i - n\bar{x}\bar{y}}{\Sigma_{i = 1}^n x_i^2 - n\bar{x}^2} $$

Primeiro, vamos estimar os parâmetros $\alpha$ e $\beta$ do modelo "manualmente". Depois, faremos com o auxílio da função `lm()` do R.


```{r}
beta_hat = (sum(x*y) - n*mean(x)*mean(y))/(sum(x^2) - n*mean(x)^2)
alpha_hat = mean(y) - beta_hat*mean(x)

alpha_hat
beta_hat
```
Logo, nosso modelo ajustado pode ser escrito como

$$ \hat{y}_i = 80.5 + 0.90x_i $$

Podemos também obter os estimadores para os coeficientes através da função `lm()`:


```{r}
lm(formula = Y ~ X, dados) %>% 
  summary()
```

> Um ponto que merece observação aqui é a forma da equação obtida (estimada) para a reta de regressão. Percebemos que nela não entra o termo de erro (resíduos). Isso ocorre porque um dos pressupostos dos modelos de regressão linear é que os resíduos têm esperança igual a zero e variância constante. Então, se estamos usando estimadores não viesados, eles "acertam" o valor do parâmetro. Dessa forma, a esperança do estimador para os resíduos deve ser igual a zero.


## Problema 1

(a) Vamos usar a função `lm()` para encontrar a reta de mínimos quadrados para $z$ (acuidade visual) em função de $x$ (idade):

```{r}
modelo = lm(formula = Z ~ X, dados)
modelo$coefficients
```

Perceba que, desta vez, decidimos não usar a função `summary()` para exibir o resultado da aplicação do modelo, uma vez que agora apenas estamos interessados nos estimadores do parâmetros do modelo.

Podemos então escrever a reta de mínimos quadrados como sendo:

$$ \hat{y}_i = 101,50 - 0,55x_i. $$

(b) Nesse caso, o parâmetro $\alpha$ significa a acuidade visual que a pessoa já tem ao nascer. O parâmetro $\beta$ significa a variação que o indivíduo comum sofre em sua acuidade visual para cada ano que se passa. Como ele é negativo aqui, isso significa que a pessoa perde sensibilidade visual a cada ano.

(c) Aqui também podemos usar a saída da função `lm()` para olhar para os resíduos do modelo. Vamos colocá-los lado a lado com os valores das variáveis de interesse:


```{r}
kable(data.frame(individuo = dados$indivíduo, X = dados$X, Z = dados$Z, e = modelo$residuals)) %>%
  kable_styling(
    full_width = F,
    bootstrap_options = c("striped", "hover", "condensed", "responsive")
  )
```
Como podemos ver, o desvio mais alto ocorre para o indivíduo nº 19, cujo módulo é igual a 19,5.


## Problema 2

(a) Primeiro, vamos admitir os dados do problema:


```{r}
dados = data.frame(
  x = c(10, 13, 5, 7, 20),
  y = c(4, 3, 6, 5, 2)
)
```

Agora, vamos obter os estimadores:

```{r}
modelo = lm(formula = y ~ x, dados)
modelo$coefficients
```

Logo, a reta de mínimos quadrados para este modelo será escrita como

$$ \hat{y}_i = 6,87 - 0,26x_i. $$

(b) Vamos usar a biblioteca `ggplot2` para fazer o gráfico pedido:


```{r}
ggplot(aes(x, y), data = dados) +
  geom_point(size = 2, color = "red") +
  stat_smooth(formula = y ~ x, method = "lm", size = 1.2) + 
  labs(
    title = "gráfico de dispersão e reta ajustada",
    subtitle = "modelo linear para aluguel versus idade"
  ) + 
  theme(text = element_text(size = 16))
```

Como vemos, apesar do reduzido número de pontos, o modelo ajustado parece apropriado.


(c) Nesse caso, o coeficiente angular nos diz que o valor médio do aluguel diminui 0,26 unidades a cada aumento de um ano na idade da casa.

(d) O coeficiente linear nesse caso nos diz que o valor médio do aluguel de casas novas é igual a 6,87 unidades.


## Problema 3

(a) Vamos primeiro escrever os dados do problema, observando que existem repetições:


```{r}
dados = data.frame(
  Pot = c(38, 43, 32, 26, 33, 19, 27, 23, 14, 21),
  Temp = c(30, 30, 50, 50, 50, 70, 70, 70, 90, 90)
)
```


(b) Agora, o gráfico de dispersão, já com a reta ajustada:


```{r}
ggplot(aes(x = Temp, y = Pot), data = dados) + 
  geom_point(size = 2, col = "black") + 
  geom_smooth(formula = y ~ x, size = 1.2, col = "orange", method = "lm") +
  labs(
    title = "Gráfico de dispersão para potência versus temperatura",
    x = "Temperatura",
    y = "Potência"
  ) + 
  theme(text = element_text(size = 16))
```

(c) Apesar dos dois pontos com resíduos maiores que os demais, percebemos que os pontos realmente se ajustam razoavelmente bem a uma linha reta.


(d) Para responder a essa pergunta, vamos primeiro obter a reta de regressão linear para potência versus temperatura:

```{r}
modelo = lm(formula = Pot ~ Temp, data = dados)

modelo$coefficients
```

Assim, podemos escrever o nosso modelo como:

$$ \hat{y}_i = 50,457 - 0,381x_i $$
Assim, vemos que a potência média será igual a zero quando a temperatura for igual a `r -modelo$coefficients[1]/modelo$coefficients[2]`.


## Problema 4

Vamos retomar os dados do exemplo 15.1:

```{r}
dados = read_excel("exemplo-15.1.xlsx")
```

Nesse caso, queremos investigar a reta de regressão para a variável $Y$ como função de $Z$:

```{r}
ggplot(aes(Z, Y), data = dados) +
  geom_point(size = 2, color = "red") +
  stat_smooth(formula = y ~ x, method = "lm", size = 1.2) + 
  labs(
    title = "gráfico de dispersão e reta ajustada",
    subtitle = "modelo linear para tempo de reação versus acuidade visual"
  ) + 
  theme(text = element_text(size = 16))
```

Vamos obter a reta de regressão:

```{r}
modelo = lm(formula = Y ~ Z, data = dados)

modelo$coefficients
```

$$ \hat{y}_i = 162,079 - 0,642z_i $$

## Problema 5

Primeiro, devemos lembrar que os dados do problema 1 são aqueles do exemplo 15.1:


```{r}
dados = read_excel("exemplo-15.1.xlsx")
```

Agora, vamos aplicar a função `anova()` para obter a tabela ANOVA para o modelo considerado no problema 1, ou seja, um modelo de regressão linear para a variável resposta $Y$ (acuidade visual), tendo como preditora a variável $X$ (idade):


```{r}
tabela = anova(lm(formula = Z ~ X, dados))
tabela
```

(a) Conforme as páginas 469 e 470 do livro-texto, sabemos que:

$$ S^2 = \dfrac{SQTot}{n-1} $$

$$ S_e^2 = \dfrac{SQRes}{n-p}  = \dfrac{SQRes}{n-2}$$
Assim, podemos calculá-los com base na tabela ANOVA acima:


```{r}
n = nrow(dados)
S2 = sum(tabela$`Sum Sq`)/(n-1)
S2
Se2 = tabela$`Sum Sq`[2]/(n-2)
Se2
```


(b) Vemos então que a redução na soma do quadrado dos resíduos não foi grande ao passar do modelo mais simples com um único parâmetro para o nosso modelo de regressão linear.

(c) Ainda com o resultado da tabela ANOVA, podemos obter:


```{r}
rsq = tabela$`Sum Sq`[1]/sum(tabela$`Sum Sq`)
rsq
```

ou seja, em torno de 16%. Essa é a proporção da variabilidade total da acuidade visual que é explicada pela relação linear com a idade.


## Problema 6

Primeiro, vamos admitir os dados do problema em um dataframe:


```{r}
dados = data.frame(
  tempo = c(10.8, 14.4, 19.6, 18, 8.4, 15.2, 11, 13.3, 23.1),
  volume = c(20.39, 24.92, 34.84, 31.72, 13.59, 30.87, 17.84, 23.22, 39.65)
)
```

(a) Para fazer o diagrama de dispersão pedido, utilizaremos o pacote `ggplot2`. Vamos aproveitar para inserir a reta de regressão no mesmo plot:


```{r}
ggplot(aes(x = tempo, y = volume), data = dados) + 
  geom_point(size = 2, color = "red") + 
  stat_smooth(formula = y ~ x, method = "lm", size = 1.2) +
  labs(
    x = "Volume",
    y = "Tempo",
    title = "Diagrama de dispersão",
    subtitle = "Tempo versus Volume"
  ) + 
  theme(text = element_text(size = 16))
```


(b) Para obeter os estimadores dos parâmetros da reta de regressão, utilizaremos novamente a função `lm()`:


```{r}
lm(formula = tempo ~ volume, data = dados)
```
Assim, a reta de regressão pedida tem a forma:

$$ \hat{t_i} = 0,6625 + 0,5393 v_i $$

(c) 

```{r}
tabela = anova(lm(formula = tempo ~ volume, data = dados))
tabela
```


(d) Conforme já visto acima, o valor de $S^2$ se relaciona com a soma dos quadrados totais, enquanto $S_e^2$ se relaciona com a soma dos quadrados dos resíduos:


```{r}
n = nrow(dados)
S2 = sum(tabela$`Sum Sq`)/(n-1)
S2
Se2 = tabela$`Sum Sq`[2]/(n-2)
Se2
```

Como vemos, $S^2 >> S_e^2$. Vamos obter o $R^2$ para o modelo:

```{r}
rsq = tabela$`Sum Sq`[1]/sum(tabela$`Sum Sq`)
rsq
```
Assim, cerca de 96% da variabilidade total do tempo gasto para acondicionar os objetos é explicada pela relação linear com o volume.

(e) Conforme os resultados da tabela ANOVA obtida, vemos que conhecer o volume do pacote ajuda sim a prever o tempo de empacotamento.


## Problema 7

Como estamos o mesmo nome para os conjuntos de dados de cada problema, estamos sobrepondo uns sobre os outros. Dessa forma, precisamos reescrever aqui os dados do problema 2:

```{r}
dados = data.frame(
  x = c(10, 13, 5, 7, 20),
  y = c(4, 3, 6, 5, 2)
)
```

Finalmente, o resultado pedido:

```{r}
tabela = anova(lm(formula = y ~ x, dados))
tabela
```



```{r}
rsq = tabela$`Sum Sq`[1]/sum(tabela$`Sum Sq`)
rsq
```


Como vemos, cerca de 94% da variação no preço dos aluguéis das casas é explicado pela respectiva idade. Indo além, vemos que esse resultado não é mero acaso, já que o p-valor do teste é $p < 0.01$.


## Problema 8

Novamente, vamos admitir os dados do problema 3:


```{r}
dados = data.frame(
  Pot = c(38, 43, 32, 26, 33, 19, 27, 23, 14, 21),
  Temp = c(30, 30, 50, 50, 50, 70, 70, 70, 90, 90)
)
```

Vamos agora obter a tabela ANOVA para o modelo ajustado e o valor de $R^2$:

```{r}
tabela = anova(lm(formula = Pot ~ Temp, dados))
tabela
```


```{r}
rsq = tabela$`Sum Sq`[1]/sum(tabela$`Sum Sq`)
rsq
```

Assim, vemos que cerca de 85% da variação na potência dos antibióticos pode ser explicada pela relação linear com a temperatura na qual eles são acondicionados, com $p < 0.01$, o que indica que esse resultado é significativo. Além disso, podemos olhar para os parâmetros do ajuste:

```{r}
lm(formula = Pot ~ Temp, dados)
```
Logo, vemos que a potência diminui com o aumento da temperatura.


## Problema 9

Vamos receber novamente os dados do problema 4:


```{r}
dados = read_excel("exemplo-15.1.xlsx")
```

Agora, vamos obter a tabela ANOVA para o modelo linear ajustado para explicar a variável $Y$ (tempo de reação ao estímulo visual) como função da acuidade visual $Z$:

```{r}
tabela = anova(lm(formula = Y ~ Z, data = dados))
tabela
```

```{r}
rsq = tabela$`Sum Sq`[1]/sum(tabela$`Sum Sq`)
rsq
```

Como vemos, aproximadamente 57% da variabilidade do tempo de resposta ao estímulo é explicada pela relação linear com a acuidade visual do indivíduo. Além disso, vemos que o resultado é significativo na maioria dos níveis de significância comumente utilizados.



## Problema 10

Primeiro, vamos novamente ler os dados do problema 5:

```{r}
dados = read_excel("exemplo-15.1.xlsx")
```


(a) Vamos obter os intervalos de confiança de 95% para os parâmetros do nosso modelo linear para acuidade visual ($Z$) em função da idade ($x$):


```{r}
lm(formula = Z ~ X, dados) %>%
  confint(parm = 2)
```

(b) E agora, o IC de 90% para o parâmetro $\alpha$:


```{r}
lm(formula = Z ~ X, dados) %>%
  confint(parm = 1, level = 0.90)
```

(c) Vamos obter a tabela ANOVA para o nosso modelo e, a partir do resultado (estatística F), rejeitar ou não a hipótese nula $H_0: \beta = 0$.

```{r}
lm(formula = Z ~ X, dados) %>%
  anova()
```

De acordo com nosso resultado, não podemos rejeitar a hipótese nula no nível de 0,05, já que o p-valor obtido foi de $\approx 0,08$. Deste modo, concluímos que o resultado não é significativo, ou seja, o grau de explicação que o nosso modelo fornece para a variável resposta aparentemente é um mero produto do acaso.


(d) Ainda usando o mesmo conjunto de dados, vamos lembrar de que queremos estimar a acuidade visual média a partir do nosso modelo linear, dado o valor de $x = 28$ e, em seguida, determinar o IC para este resultado:

```{r}
lm(formula = Z ~ X, dados) %>%
  predict(newdata = data.frame(X = 28), interval = "confidence", level = 0.95)
```
O que essa função está fazendo é calcular o valor da variável resposta para $x = 28$ e, em seguida, determinar o intervalo de confiança para a média condicional (resposta), dada pelo nosso modelo.

(e) Na mesma linha, vamos obter agora o intervalo de predição para a acuidade visual (variável resposta) do grupo etário com 28 anos (variável explicativa):

```{r}
lm(formula = Y ~ X, dados) %>%
  predict(newdata = data.frame(X = 28), interval = "predict", level = 0.95)
```
Esse resultado nos diz que, se obtivermos um número grande de amostras de pares $(x, Z)$, todas do mesmo tamanho $n$, cerca de 95% dos intervalos de predição assim construídos conterão o verdadeiro valor da variável resposta, dado aquele valor da variável explicativa $x$.


## Problema 11

Como o conjunto de dados é o mesmo do problema anterior, vamos apenas olhar novamente para a tabela ANOVA construída no problema 9:


```{r}
tabela = anova(lm(formula = Y ~ Z, data = dados))
tabela
```

Vamos também calcular o valor do coeficiente de explicação $R^2$ do nosso modelo:

```{r}
tabela$`Sum Sq`[1]/sum(tabela$`Sum Sq`)
```

Portanto, vemos que cerca de 57% da variabilidade da nossa variável reposta $Y$ é explicada pelo nosso modelo. Ainda, olhando para a estatística F da nossa tabela ANOVA, vemos que o resultado é siginificativo, já que $p < 0,05$. Assim, podemos rejeitar a hipótese nula de que $\beta = 0$ e concluir que a acuidade visual pode explicar o tempo de resposta a um estímulo visual segundo o nosso modelo.


## Problema 12

Para saber se a quantidade de fertilizante de fato nos ajuda a explicar o comportamento da produção de soja, precisamos verificar se o resultado para o nosso parâmetro $\beta$ é significativo. Como nos foi dado o valor da estatística $t$ para cada parâmetro estimado, precisamos apenas ver se ele está dentro ou fora da regisão crítica para rejeição da hipótese nula $H_0: \beta = 0$.


```{r}
cat(
  "Região de aceitação:",
  qt(p = c(0.025, 0.975), df = 20-2)
)
```

Como o valor da estatística $t$ para o parâmetro $\beta$ está dentro da regiçaõ de aceitação (ou fora da região crítica), não podemos rejeitar a hipótese nula de que $\beta = 0$. Em outras palavras, concluímos que o nosso modelo provavelmente não serve para explicar o comportamento da produção de soja como função da quantidade de fertilizante utilizado.

Podemos também olhar para o p-valor, o que irá nos levar à mesma conclusão:

```{r}
pt(1.65, df = 20-2)
```


## Análise de resíduos

Para verificar se um modelo de regressão linear ajustado atende aos pressupostos, podemos aplicar a função `plot()` à saída de `lm()`. Para entendermos qual será o resultado, podemos rodar o comando `?plot.lm`.


- A função `par()` é usada para definir parâmetros de gráficos

- O argumento `mfrow` divide o gráfico conforme uma matriz $n_r \times c_c$, plotando primeiro os quadros horizontais.

- A função `plot()`, quando aplicada a um objeto do tipo `lm()`, dispõe de 6 saídas:


1 - gráfico de dispersão para resíduos contra valores ajustados

2 - gráfico de localização da escala da raíz dos resíduos versus valores ajustados

3 - q-q plot para a distribuição normal

4 - gráfico de distâncias de Cook versus rótulos de linha

5 - resíduos versus alavancagem

6 - distâncias de Cook versus alavancagem


Por padrão, a saída apresenta as 3 primeiras e a quinta opções. Porém, outras podem ser selecionadas com o argumento `which`.


## Problema 13

Primeiro, vamos novamente obter o conjunto de dados referente ao exemplo 15.1:


```{r}
dados = read_excel("exemplo-15.1.xlsx")
```

Nesse caso, queremos ajustar um modelo linear para $Z$ como função de $x$:

```{r}
modelo = lm(formula = Z ~ X, dados)
```

Agora, vamos construir os 3 tipos de resíduos apresentados no livro:


```{r}
n = nrow(dados)
e = dados$Z - as.vector(modelo$fitted.values) #residuos
se = sqrt(sum(e^2)/(n-2)) #Estimador da variância dos resíduos
z = e/se #residuos padronizados
v = 1/n + (dados$X-mean(dados$X))^2/sum((dados$X-mean(dados$X))^2)
r = e/(se*sqrt(1-v)) #residuo estudentizado
```

Para plotar os 3 tipos de resíduos calculados como função dos valores ajustados, vamos usar a biblioteca `ggplot`:

```{r}
ei = dados %>%
  ggplot(aes(x = X, y = e)) +
  geom_point(color = "red", size = 2) +
  geom_hline(yintercept = 0, color = "darkgray") + 
  labs(
    x = "idade",
    y = "resíduos"
  )

zi = dados %>%
  ggplot(aes(x = X, y = z)) +
  geom_point(color = "green", size = 2) +
  geom_hline(yintercept = 0, color = "darkgray") + 
  labs(
    x = "idade",
    y = "resíduos padronizados"
  )

ri = dados %>%
  ggplot(aes(x = X, y = r)) +
  geom_point(color = "blue", size = 2) +
  geom_hline(yintercept = 0, color = "darkgray") + 
  labs(
    x = "idade",
    y = "resíduos estudentizados"
  )

cowplot::plot_grid(ei, zi, ri)
```

Olhando apenas para os resíduos versus valores ajustados, não vemos uma violação clara ao modelo. É necessário olhar para outros gráficos de resíduos, como os que são mostrados abaixo:

```{r}
par(mfrow = c(2,2))
plot(modelo, which = c(1:4), pch = 16)
```

Olhando agora para a curva dos resíduos padronizados, vemos, portanto, que a hipótese de homocedasticidade parece ser violada, já que a variância diminui com x.


## Problema 14

(a) Aqui, vemos uma violação da hipótese de homocedasticidade, já que a variância dos resíduos parece depender de x.

(b) Nesse caso, o modelo matemático adotado parece ser inadequado, já que a média dos resíduos varia com os valores ajustados (ou com x), o que indica que o modelo ajustado não descreve adequadamente como y se comporta quando x muda. 

(c) Mesma interpretação que em (b).

(d) Os resíduos parecem ter média zero e variância constante. Contudo, existe um dado discrepante.


## Problema 15

Vamos receber os dados do problema:


```{r}
dados = data.frame(
  preditor = c(11, 20, 14, 22, 12, 25, 15, 
               14, 19, 21, 18, 22, 16, 21
               ),
  residuo = c(-1, -2, 3, -3, -1, 5, 0,
              0, 3, -2, 2, -5, 0, 1
              ),
  ordem = c(9, 6, 13, 1, 7, 14, 8,
            3, 12, 4, 11, 2, 10, 5
            )
)
```

(a) Vamos usar a biblioteca `ggplot2` para obter o gráfico dos resíduos versus variável predidora:


```{r}
dados %>%
  ggplot(aes(x = preditor, y = residuo)) + 
  geom_point(size = 2, col = "orange") + 
  geom_hline(yintercept = 0, color = "darkgray") +
  labs(
    x = "preditor",
    y = "residuos"
  ) +
  theme(text = element_text(size = 16))
```

Apenas com o resultado do gráfico, não dar para fornecer um posicionamento conclusivo. Porém, aparentemente, os resíduos não possuem variância constante.


(b)


```{r}
dados %>%
  ggplot(aes(x = ordem, y = residuo)) + 
  geom_point(size = 2, col = "orange") + 
  geom_hline(yintercept = 0, color = "darkgray") +
  labs(
    x = "preditor",
    y = "residuos"
  ) +
  theme(text = element_text(size = 16))
```

Aqui, vemos que os resíduos aumentam no decorrer da coleta dos dados.



## Exemplo 16.9 (página 489)

Vamos usar os dados desse exemplo do livro para obter o estimador de mínimos quadrados e o modelo linear de regressão linear para o caso simples em que $\alpha = 0$. Vamos admitir os dados do problema:

```{r}
dados = data.frame(
  x = c(119, 155, 174, 190, 196, 233, 272, 253, 276),
  y = c(112, 152, 172, 183, 192, 228, 263, 239, 263)
)
```


Agora, vamos obter o estimador para o parâmetro $\beta$ do nosso modelo linear com intercepto nulo:

```{r}
modelo = lm(formula = y ~ x - 1, dados)
modelo
```
Obtivemos então o resultado 

$$ \hat{y} = 0,9648x. $$
Vamos também obter a tabela ANOVA para o modelo, a fim de avaliar a estatística F e o respectivo p-valor, a fim de inferir a significância do valor de $\beta$ encontrado:

```{r}
anova(modelo)
```
Como o p-valor encontrado é essencialmente nulo, vemos que o resultado é significativo. Além disso, também com o resultado da tabela ANOVA obtida, vemos que o modelo adotado explica a maior parte da variância de x.


Podemos também obter um intervalo de confiança para $\beta$, com 95% de nível de confiança:

```{r}
confint(modelo)
```
Vamos também plotar o modelo ajustado, com o auxílio da biblioteca `ggplot2`:


```{r}
dados %>%
  ggplot(aes(x = x, y = y, dados)) +
  geom_point(size = 2, col = "orange") + 
  geom_smooth(formula = y ~ x - 1, col = "black", method = "lm") +
  labs(
    title = "Modelo linear com intercepto nulo"
  ) +
  theme(text = element_text(size = 16))
```

Por fim, a análise dos resíduos do modelo:

```{r}
par(mfrow = c(2,2))
plot(modelo, which = c(1:4), pch = 16)
```

Vemos, portanto, que os resíduos do modelo parecem violar a hipótese de média zero e variância constante.



# Problemas Suplementares

## Problema 16

Vamos chamar novamente os dados referidos no problema (exemplo 15.1), já que estamos sobrescrevendo os datasets ao longo do relatório:


```{r}
dados = read_excel("exemplo-15.1.xlsx")
```


(a) Agora, vamos novamente obter os estimadores de mínimos quadrados para a reta de regressão de Z como função de X:

```{r}
modelo = lm(Z ~ X, dados)
modelo
```
Assim, a reta de regressão estimada para os nossos dados será

$$ \hat{z} = 101,50 - 0,55*x. $$

Para construir o IC de 95% para a acuidade visual média dos indivíduos com 18 anos de idade, vamos usar a função `predict()`


```{r}
modelo %>%
  predict(newdata = data.frame(X = 18), interval = "confidence", level = 0.95)
```
Assim, o IC procurado é

$$ IC(E(Z| x = 18)) = [82,88; 100,32] $$

(b) Na mesma linha do item (a),

```{r}
modelo %>%
  predict(newdata = data.frame(X = 30), interval = "confidence", level = 0.95)
```

$$ IC(E(Z| x = 30)) = [80,57; 89,43] $$

(c) 

```{r}
modelo %>%
  predict(newdata = data.frame(X = 80), interval = "confidence", level = 0.95)
```

$$ IC(E(Z| x = 80)) = [25,89; 89,10] $$

Como podemos ver, o IC de 95% é muito mais largo para o grupo com 80 anos do que para os dois grupos analisados nos itens (a) e (b). Isso ocorre porque o grupo com 80 anos está muito afastado da média de idade do conjunto de dados como um todo. Essa informação é levada em conta no cálculo do IC.


## Problema 17

Vamos novamente admitir os dados do problema 6 e ajustá-los ao modelo linear usando o método de regressão linear:

```{r}
dados = data.frame(
  tempo = c(10.8, 14.4, 19.6, 18, 8.4, 15.2, 11, 13.3, 23.1),
  volume = c(20.39, 24.92, 34.84, 31.72, 13.59, 30.87, 17.84, 23.22, 39.65)
)
```


```{r}
dados %>%
  lm(formula = tempo ~ volume) %>%
  predict(newdata = data.frame(volume = 30), interval = "confidence")
```
Aqui, usamos a função predict para nos fornecer uma previsão do valor ajustado quando a variável preditora (volume) é igual a 30. As outras duas são os valores da esquerda e direita para um intervalo de confiança de 95% em torno deste valor ajustado, que não foram pedidos no problema.


## Problema 18

```{r}
dados = data.frame(
  meses = c(1:10),
  erros = c(30, 28, 24, 20, 18, 14, 13, 10, 7, 6)
)
```

(a) Vamos plotar o diagrama de dispersão já com a reta de regressão linear ajustada pelo método de mínimos quadrados:


```{r}
dados %>%
  ggplot(aes(x = meses, y = erros)) +
  geom_point(size = 2, col = "orange") + 
  stat_smooth(formula = y ~ x, method = "lm") +
  labs(
    title = "Reta de regressão linear ajustada",
    subtitle = "Método de MQO"
  ) +
  theme(text = element_text(size = 16))
```

(b) Para determinar os coeficientes da equação de mínimos quadrados, vamos utilizar a função `lm()`:


```{r}
lm(formula = erros ~ meses, dados)
```

Assim, a reta de mínimos quadrados ordinários pedida é

$$ \hat{y} = 32,27 - 2,78*x. $$

(c) Já obtido em (a).


(d) Primeiro, vamos obter as duas médias amostrais:

```{r}
cat(
  "(xbar, ybar) =",
  "[",
  mean(dados$meses), mean(dados$erros),
  "]"
)
```
Para ver a posição desses valores relativamente à reta de regressão, vamos plotá-la novamente, desta vez traçando duas retas em $(\bar{x}, \bar{y})$:


```{r}
dados %>%
  ggplot(aes(x = meses, y = erros)) +
  geom_point(size = 2, col = "orange") + 
  stat_smooth(formula = y ~ x, method = "lm") +
  geom_vline(xintercept = mean(dados$meses), col = "red") +
  geom_hline(yintercept = mean(dados$erros), col = "red") +
  labs(
    title = "Reta de regressão linear ajustada",
    subtitle = "Método de MQO"
  ) +
  theme_classic() +
  theme(text = element_text(size = 16))
```


Como vemos, o ponto $(\bar{x}, \bar{y})$ passa pela reta de regressão. Isso decorre do ajuste de mínimos quadrados, em que os estimadores dos parâmetros da equação de regressão dependem das médias $\bar{x}$ e $\bar{y}$.

(e) Para determinar o número esperado de erros para um digitador com x = 5 meses de experiência, precisamos ver o valor do ajuste da nossa reta de mínimos quadrados quando $x = 5$. Para tanto, vamos usar a função `predict()`:


```{r}
dados %>%
  lm(formula = erros ~ meses) %>%
  predict(newdata = data.frame(meses = 5), interval = "confidence", level = 0.95)
```

Novamente, usamos a função `predict()` para estimar o número médio de erros esperados para um digitador com $x = 5$ meses de experiência. A saída da função também fornece o intervalo de confiança para essa medida.


## Problema 19


Vamos primeiro fornecer os dados do problema ao R:


```{r}
dados = data.frame(
  renda = c(3, 5, 10, 20, 30, 50, 70, 100, 150, 200),
  gasto = c(1.5, 2, 6, 10, 15, 20, 25, 40, 60, 80)
)
```

Agora, vamos obter a reta de regressão a partir do ajuste de mínimos quadrados:


```{r}
modelo = lm(formula = gasto ~ renda, dados)
modelo
```

Assim, a equação procurada tem a forma

$$ \hat{y} = 0,95 + 0,39*x $$

(a) Assim como feito no problema anterior, para obter uma estimativa do gasto médio com alimentação (variável resposta) para uma família com renda x = 170 (variável preditora), podemos usar a função `predict()`:


```{r}
modelo %>%
  predict(newdata = data.frame(renda = 170), interval = "confidence")
```

Novamente, o resultado nos mostra o valor médio previsto pelo modelo quando a renda é igual a 170, bem como o intervalo de confiança de 95% em torno deste valor.

Também é interessante observar que a função `predict()`, quando não fornecemos o argumento `newdata`, nos dá como resultado todos os valores ajustados e os respectivos intervalos de confiança.


(b) Aqui, precisamos fazer o mesmo que no problema anterior, comn a diferença de que agora estamos fazendo uma previsão para o gasto médio com alimentação para um valor da variável preditora que está fora dos nossos dados. Isto é chamado de extrapolação:


```{r}
modelo %>%
  predict(newdata = data.frame(renda = 1000), interval = "confidence")
```

Para opinar se este valor parece razoável ou não, precisamos compará-lo com os demais valores ajustados:


```{r}
predict(modelo, interval = "confidence")
```

Levando em consideração que o valor da variável preditora aqui é 5 vezes o maior valor observado nos dados e, como a relação é linear, é razoável esperar que o gasto médio com alimentação para uma família com renda igual a 1000 esteja em torno de 400, já que o gasto médio previsto pelo modelo quando a renda é igual a 200 é cerca de 80.


(c) Apesar do resultado anterior parecer razoável do ponto de vista do modelo, sabemos que essa previsão não é realística, já que, na prática, o gasto com alimentação tende a se estabilizar após certo ponto, isto é, existe um limite em que o gasto com alimentação não cresce mais com o aumento da renda.


## Problema 20

Feito direto no livro.


## Problema 21

Conforme o modelo ajustado, considerando a interpretação do parâmetro $\beta$, quando se aumenta os anúncios em uma unidade, em média, aumenta-se a quantidade de carros vendidos em 1,516.


## Problema 22

Vamos primeiro passar os dados do problema para o R:

```{r}
dados = data.frame(
  X = c(0.5, 0.5, 1, 1, 1, 4, 4, 4, 4.5, 4.5, 4.5, 5, 5, 5, 5.5, 6, 6),
  Y = c(163, 182, 978, 466, 549, 495, 723, 681, 619, 1049, 1033, 890, 1522, 1194, 987, 764, 1373)
)
```

(a) Agora, vamos fazer o ajuste do modelo utilizando regressão linear:

```{r}
modelo = lm(formula = Y ~ X, dados)
modelo
```

Assim, o modelo ajustado é

$$ \hat{y} = 323,6 + 131,7*x. $$
Vamos testar a hipótese nula de que $\beta = 0$, a qual, se não rejeitada, indicaria que a variável resposta não seria explicada de acordo com a relação linear dada com a variável preditora. Para fazer esse teste, vamos usar a estatística $F$
dada, a qual tem distribuição $F(1, n-2)$. Para tanto, vamos calcular o p-valor, lembrando que esse é um teste unilateral à direita. Ou seja, a hipótese nula apenas será rejeitada para valores grandes da estatística $F$, determinados de acordo com a significância do teste. Podemos obter a estatística $F$ e o p-valor associado a partir da tabela anova para o modelo:


```{r}
tabela = anova(modelo)
tabela
```

Como vemos, $p < 0,01$, indicando que devemos rejeitar a hipótese nula de que $\beta = 0$ e, portanto, concluímos que a relação obtida entre as duas variáveis não é mero acaso.


(b) Para responder a essa pergunta, vamos olhar para o valor de $R^2$ para o nosso modelo, o qual pode ser obtido da tabela ANOVA como sendo

$$ R^2 = \dfrac{SQReg}{SQTot} $$

```{r}
rsq = tabela$`Sum Sq`[1]/sum(tabela$`Sum Sq`)
rsq
```
Ou seja, o modelo ajustado explica cerca de 48% da variabilidade da variável preditora. Como o valor dessa grandeza pode estar entre 0 e 1, sendo que a unidade indica a perfeição do modelo, concluímos que esse modelo aparentemente não é o mais apropriado, já que o valor obtido está mais perto de zero do que de 1.

O valor de $R^2$ também pode ser obtido de maneira mais direta, por meio da função `summary()`:


```{r}
summary(modelo)
```
(c) Se queremos saber a previsão do custo médio de mantenção para tratores com 5 anos, de acordo com nosso modelo, podemos usar a função `predict()`:


```{r}
modelo %>%
  predict(newdata = data.frame(X = 5), interval = "confidence", level = 0.90)
```

O resultado já contêm o intervalo de confiança de 90% pedido.


(d) Para responder a essa pergunta, não podemos recorrer a estatística $F$ que resulta da tabela ANOVA, já que aquela apenas serve para testar a hipótese nula $H_0: \beta_1 = 0$ contra a alternativa $H_1: \beta_1 > 0$. Devemos, ao invés disso, calcular o valor da estatística $t(\hat{\alpha})$ observada e então obter o p-valor associado.

$$ H_0: \beta_0 = 300 $$

$$ H_1: \beta_0 > 300 $$
Vamos usar a expressão dada na página 478:

$$ t({\hat{\alpha}}) = \dfrac{\hat{\alpha} - \alpha}{S_e}\sqrt{\dfrac{n\sum(x_i - \bar{x})^2}{\sum x_i^2}} $$

Lembrando que a estimativa do desvio padrão dos resíduos é igual a média dos quadrados do resíduo, e essa informação está na nossa tabela ANOVA já obtida. Além disso, o estimador $\hat{\alpha}$ pode ser obtido diretamente do modelo ajustado:


```{r}
n = nrow(dados)
S_e = sqrt(tabela$`Mean Sq`[2]) #estimativa do desvio padrão dos resíduos
alpha_hat = as.double(modelo$coefficients[1]) #parâmetro alpha estimado
t_alpha = ((alpha_hat - 300)/S_e)*sqrt(n*sum((dados$X - mean(dados$X))^2)/sum(dados$X^2))
```


Agora que já temos a estatística do teste em mãos, precisamos apenas lembrar que ela tem distribuição t de Student com $n-2$ graus de liberdade para então calcular o p-valor. Além disso, como o teste é unilateral à direita, precisamos fornecer o argumento `lower.tail = FALSE`:


```{r}
pt(t_alpha, df = n-2, lower.tail = F)
```
Como o valor p calculado é maior que a significância do teste, que é de 0,05, não podemos rejeitar a hipótese nula de que $\beta_0 = 300$.

O resultado faz sentido, já que o valor estimado para este parâmetro foi igual a 323,62 e, devido à variabilidade do estimador, não temos poder estatístico para rejeitar a hipótese nula.


## Problema 23

Primeiro, vamos carregar os dados para o R:


```{r}
dados = data.frame(
  pais = 15:21,
  filhos = c(15.4, 15.7, 16, 16.3, 16.6, 17, 17.3)
)
```


Agora, vamos obter as estimativas dos parâmetros da reta de regressão linear:


```{r}
modelo = lm(formula = filhos ~ pais, dados)
modelo
```

Logo, a reta de regressão linear ajustada tem a forma


$$ \hat{y} = 10,61 + 0,32*x $$

De acordo com o modelo estimado, a cada alteração de 1 centésimo de polegada no diâmetro médio das ervilhas-pais, aumenta-se 0,32 centésimo de polegada no diâmetro das ervilhas-filhas. Além disso, o diâmetro médio mínimo estimado para as ervilhas-filhas é de cerca de 10,61 centésimos de polegada.


## Problema 24


O pesquisador poderia obter várias amostras de medidas feitas pelo instrumento para concentrações conhecidas do ácido no sangue. Assim, se o instrumento estiver calibrado, a relação entre a concentração medida (variável dependente, $Y$) e a concentração real (variável independente, $x$) deveria ser uma linha reta com $\beta \approx 1$ e $\alpha \approx 0$.

Assim, as hipóteses a serem adotadas sobre os parâmetros do respectivo modelo de regressão linear seriam:


Para o parâmetro $\alpha$:

$$ H_0: \alpha = 0 $$
$$ H_1: \alpha \neq 0 $$
Para o parâmetro $\beta$:


$$ H_0: \beta = 1 $$

$$ H_1: \beta \neq 1, $$

dados o modelo com a forma matemática


$$ \hat{y} = \hat{\alpha} + \hat{\beta}*x. $$

## Problema 25

Primeiramente, vamos carregar os dados:


```{r}
dados = data.frame(
  X = c(rep(1, 4), rep(3, 5), rep(5, 3), rep(10, 4), rep(15, 4)),
  Y = c(1.1, 0.7, 1.8, 0.4, 
        3, 1.4, 4.9, 4.4, 4.5,
        7.3, 8.2, 6.2,
        12, 13.1, 12.6, 13.2,
        18.7, 19.7, 17.4, 17.1)
)
```

Agora, vamos ajustar os parâmetros do modelo:


```{r}
modelo = lm(formula = Y ~ X, dados)
modelo
```
Logo, o modelo ajustado tem a forma:


$$ \hat{y} = 0,16 + 1,23*x. $$

Finalmente, vamos testar as hipóteses pedidas. Para isso, temos que calcular a estatística $t(\hat{\beta})$ observada para a amostra e, a partir disso, calcular o p-valor:


```{r}
tabela = anova(modelo)
n = nrow(dados)
S_e = sqrt(tabela$`Mean Sq`[2]) #estimativa do desvio padrão dos resíduos
beta_hat = as.double(modelo$coefficients[2]) #parâmetro beta estimado
t_beta = ((beta_hat - 1)/S_e)*sqrt(sum((dados$X - mean(dados$X))^2))
```


E então, calculamos o p-valor, lembrando que estamos interessados apenas no teste unicaudal:


```{r}
pt(t_beta, df = n-2, lower.tail = F)
```

Logo, como $p < 0,01$, decidimos por rejeitar a hipótese nula de que $\beta_1 = 1$ e, portanto, concluímos que o instrumento não está calibrado, já que, para isso, o valor de $\beta$ deveria ser próximo de 1 e o resultado significativo.


## Problema 26


(a) Esse modelo seria adequado apenas para uma faixa de precipitação. A partir de certo valor de precipitação, a produção de trigo seria prejudicada pelo excesso de água.


(b) Uma relação matemática mais adequada provavelmente seria algo com um termo senoidal, conforme mostrada abaixo:


```{r}
x = seq(0, pi, by = 0.1)
y = sin(x)
plot(x, y, pch = 16)
```


## Problema 27

Vamos primeiro obter os dados:


```{r}
dados = data.frame(
  Y = c(17, 21, 49, 54, 64, 48, 34, 63, 62, 72, 61, 91),
  log_X = c(rep(0.36, 4), rep(0.56, 4), rep(0.76, 4))
)
```

Agora, vamos obter os estimadores dos parâmetros ajustados ao modelo linear:


```{r}
modelo = lm(formula = Y ~ log_X, dados)
modelo
```
Logo, nosso modelo tem a forma

$$ \hat{y} = 2,25 + 90,62*\log{x}. $$

Vamos obter também a tabela ANOVA para o nosso modelo:


```{r}
tabela = anova(modelo)
tabela
```
Olhando para a tabela, de cara já rejeitamos a hipóteses $H_0: \beta_1 = 0$, já que o p-valor associada à estatística F obtida é menor que 0,01. Portando, concluímos que o logaritmo da dose de insulina aplicada ajuda a prever a queda nos níveis de açucar no sangue. Podemos também observar a saída da função `summary()` aplicada ao modelo:


```{r}
summary(modelo)
```
Aqui, vemos novamente o valor p associado à estatística F e o $R^2$, que indica que cerca de 54% da variação na queda dos níveis de açucar no sangue é explicado pela log-dose de insulina.


## Problema 28


Primeiro, vamos passar os dados do problema para o R:


```{r}
dados = data.frame(
  trimestre = 1:8,
  Y = c(25, 13, 8, 20, 25, 12, 10, 15),
  X = c(11, 5, 3, 9, 12, 6, 5, 9),
  Z = c(2, 13, 16, 7, 4, 10, 13, 4)
)
```

(a)

```{r}
p1 = ggplot(aes(x = X, y = Y), data = dados) + 
  geom_point(size = 2.5, col = "orange") + 
  labs(
    x = "Desp. c/ propag.",
    y = "vendas"
  ) + 
  theme(text = element_text(size = 16))

p2 = ggplot(aes(x = Z, y = Y), data = dados) + 
  geom_point(size = 2.5, col = "green") + 
  labs(
    x = "Temp. média",
    y = "vendas"
  ) + 
  theme(text = element_text(size = 16))

cowplot::plot_grid(p1, p2)
```

Como podemos ver na figura acima, o volume de vendas parece aumentar com o aumento da despesa com propaganda e parece diminuir com o aumento da temperatura média, ambos com uma relação gráfica aparentemente linear.


(b) Vamos fazer isso com o auxílio da função `lm()`:


```{r}
mod_vendas_propag = lm(Y ~ X, dados)
mod_vendas_propag
mod_vendas_temp = lm(Y ~ Z, dados)
mod_vendas_temp
```

Assim, as retas de regressão linear pedidas são:


$$ \hat{y} = 1,313 + 1,958x $$ e

$$ \hat{y} = 25,710 - 1,126z $$
Podemos também plotar os modelos lado a lado para comparar:



```{r}
p1 = ggplot(aes(x = X, y = Y), data = dados) + 
  geom_point(size = 2.2, col = "red") +
  stat_smooth(method = "lm", formula = y ~ x) + 
  labs(
    x = "Desp. c/ propag.",
    y = "vendas"
  ) + 
  theme(text = element_text(size = 16))

p2 = ggplot(aes(x = X, y = Z), data = dados) + 
  geom_point(size = 2.2, col = "red") + 
  stat_smooth(method = "lm", formula = y ~ x, col = "green") + 
  labs(
    x = "Temp. Média",
    y = "vendas"
  ) + 
  theme(text = element_text(size = 16))

cowplot::plot_grid(p1, p2)
```

(c) Olhando para as duas retas, vemos que os resíduos são semelhantes, sendo que a maior diferença entre elas são suas inclinações, já que uma é positiva e a outra é negativa. Para decidir sobre qual modelo utilizar dentre os dois, vamos ver o resumo estatístico de ambos:


```{r}
summary(mod_vendas_propag)
summary(mod_vendas_temp)
```

Ao comparar os resultados, vemos que ambos os modelos parecem bons, já que os dois têm valor de $R^2$ alto e ambos os resultados são significantes, com $p < 0,01$. Contudo, no primeiro modelo (vendas como função da despesa com propaganda), o valor da estatística $F$ é maior, tendo portanto um menor valor de p associado. Além disso, no primeiro modelo, o coeficiente de explicação do modelo $R^2$ é maior.

Pelo exposto, escolhemos o modelo $y = f(x)$ como sendo o mais apropriado.


(d) Aqui, queremos avaliar a resposta dos modelos para os valores dados da respectiva variável preditora. Para isso, vamos utilizar a função `predict()`:


```{r}
cat("Previsão do modelo vendas em função do gasto com propaganda:",
    predict(mod_vendas_propag, newdata = data.frame(X = 8), interval = "confidence"),
    "\n\n",
    "Previsão do modelo vendas em função da temperatura média:",
    predict(mod_vendas_temp, newdata = data.frame(Z = 10), interval = "confidence")
    )
```


## Problema 29


(a) Para encontrar os estimadores do modelo, vamos usar a equação 16.33, combinada com as 16.14. Primeiramente, notamos que há uma forma mais direta de obter o estimador do parâmetro $b$ a partir da soma dos quadrados devido à regressão:


$$ \hat{a} = \bar{y} - \hat{b} \bar{x} $$

$$ SQReg = \hat{b}^2 \sum_{i = 1}^n (x_i - \bar{x})^2 = \hat{b}^2 (n-1) s_x^2. $$

Como $R^2 = \frac{SQReg}{SQTot}$, podemos escrever


$$ \hat{b}^2 = \dfrac{SQReg}{(n-1) s_x^2} = \dfrac{r^2 SQTot}{(n-1) s_x^2}. $$

Ainda, como $s_y^2 = \frac{SQTot}{n-1}$,


$$ \hat{b}^2 = \dfrac{r^2 s_y^2}{s_x^2}.  $$

Finalmente, vamos calcular os valores pedidos no R:


```{r}
n = 7
xbar = 400
ybar = 60
sx = 216.02
sy = 13.84
rsq = 0.922
b = rsq*sy/sx
a = ybar - b*xbar
```

Logo, o modelo procurado é


$$ \hat{y} = 36,372 + 0,059x $$
 
(b) Como não temos o conjunto de dados para aplicar as funções `lm()` e `anova()`, vamos calcular as entradas da tabela ANOVA, lembrando que teremos $n-2 = 5$ graus de liberdade associados à aos resíduos e $n-1 - (n-2) = 1$ grau de liberdade associado à regressão. 

Pelas equações dadas acima, temos:


```{r}
SQReg = (n-1)*sx^2*b^2
QMReg = SQReg/1
SQTot = (n-1)*sy^2
SQRes = SQTot - SQReg
QMRes = SQRes/(n-2)
se2 = QMRes
F_ = QMReg/se2
```


(c) Primeiramente vamos lembrar que a estatística F nos permite testar a hipótese $H_0: b = 0$ contra a hipótese alternativa $H_1: b \neq 0$. Desse modo, como já temos o valor de $R^2$, que é 0,922, o que precisamos fazer agora é se o resultado é significativo, ou seja, se de fato a quantidade de fertilizante pode ser usada para prever a produtividade. Vamos então calcular o p valor associado à estatística F:


```{r}
pf(F_, 1, n-2, lower.tail = FALSE)
```

Logo, dado que $p < 0,01$, rejeitamos a hipótese nula e concluímos que o modelo de fato serve para explicar a produtividade em função da quantidade de fertilizante.

## Problema 30

Vamos carregar os dados referentes ao problema:

```{r}
dados = data.frame(
  N = 1:25,
  x = c(35.3, 29.7, 30.8, 58.8, 61.4, 71.3, 74.4, 76.7, 70.7, 57.5, 46.4, 28.9, 28.1, 39.1, 46.8, 48.5, 59.3, 70, 70, 74.5, 72.1, 58.1, 44.6, 33.4, 28.6
        ),
  y = c(10.98, 11.13, 12.51, 8.4, 9.27, 8.73, 6.36, 8.5, 7.82, 9.14, 8.24, 12.19, 11.88, 9.57, 10.94, 9.58, 10.09, 8.11, 6.83, 8.88, 7.68, 8.47, 8.86, 10.36, 11.08
        )
)
```

Agora, vamos obter o ajuste de mínimos quadrados para o modelo linear desejado:


```{r}
modelo = lm(y ~ x, dados)
summary(modelo)
```

A equação que define o modelo é, portanto,

$$ \hat{y} = 13,62 - 0,08x $$

```{r}
par(mfrow = c(2,2))
plot(dados$x, dados$y, pch = 16, xlab = "temperatura", ylab = "qtde vapor", main = "fitted model")
abline(modelo)
plot(modelo, which = 1:3, pch = 16)
```


## Problema 31

Primeiramente, temos que lembrar que o modelo 16.71 não é linear nos parâmetros. Por esse motivo, precisamos linearizá-lo por meio da transformação logarítmica. Como isso já está feito no livro, vamos apenas fazer o ajuste do modelo $y_i^* = \alpha^* + \beta x_i + \epsilon_i^*$, no qual $y_i^* = \log y_i$ e $\alpha^* = \log \alpha$.

Dessa forma, vamos carregar os dados necessários:


```{r}
dados = data.frame(
  ano = c(seq(-9, -1, 2), seq(1, 9, 2)),
  logy = c(2.2, 3.2, 4.3, 4.8, 5.2, 5.6, 5.9, 6.4, 7.1, 7.9)
)
```

Agora, vamos obter as estimativas do modelo:


```{r}
modelo = lm(logy ~ ano, dados)
summary(modelo)
```
Agora, vamos obter a tabela ANOVA pedida:


```{r}
anova(modelo)
```
Por fim, vamos obter os intervalos de confiança para os parâmetros do modelo, com o auxílio da função `confint()`


```{r}
confint(modelo)
```


## Problema 32

Nesse caso, como $\alpha^* = \log \alpha$, para descobrirmos o intervalo de confiança para $\alpha$, basta calcularmos a exponencial dos extremos do intervalo já obtido:


```{r}
exp(confint(modelo, 1))
```


## Problema 33

De volta aos dados do exemplo 15.1 do livro:


```{r}
dados = read_excel("exemplo-15.1.xlsx")
```


(a) Primeiro, vamos ajustar o modelo de regressão linear para $Y$ em função de $X$:


```{r}
modelo = lm(Y ~ X, dados)
```

Agora, vamos construir o IC pedido através da função `predict()`


```{r}
predict(modelo, newdata = data.frame(X = 28), interval = "confidence")
```

(b) De maneira semelhante, vamos obter agora o intervalo de predição de $Y$ para $X = 28$. O códito utilizado será o mesmo do item anterior, trocando o argumento `interval = confidence` por `interval = predict`:


```{r}
predict(modelo, newdata = data.frame(X = 28), interval = "predict")
```


(c) Comparando os resultados, vemos que as estimativas pontuais são idênticas. Contudo, as larguras dos intervalos são diferentes. Mais especificamente, o intervalo de predição tem sempre maior amplitude que o intervalo de confiança. De fato, são duas coisas distintas: no caso do item (a), estamos interessados no intervalo de confiança para a resposta MÉDIA quando a variável preditora é igual a 28. No item (b), por outro lado, estamos interessados no intervalo de "confiança" para uma medida futura da resposta $Y$ quando $X = 28$, o que envolve também a variância  do erro (ou resíduo). No primeiro caso, como o valor esperado do resíduo é zero, temos um termo a menos.


## Problema 34

Vamos carregar novamente os dados do problema 3:

```{r}
dados = data.frame(
  Pot = c(38, 43, 32, 26, 33, 19, 27, 23, 14, 21),
  Temp = c(30, 30, 50, 50, 50, 70, 70, 70, 90, 90)
)
```


Agora, para obter os gráficos solicitados, precisamos escrever as expressões para os intervalos de confiança e de predição, substituir as grandezas que já temos e deixar o resultado como função da variável independente (temperatura). Após isso, basta plotarmos o gráfico desse resultado para alguns valores de temperatura previamente definidos. 

Tudo isso pode ser facilitado pelo uso da função `predict()`. Com ela, podemos obter os intervalos de confiança e de predição muito facilmente, bastando fornecer como entrada o modelo, os valores da variável independente para predição e o tipo de intervalo - predição ou confiança:


```{r}
conf = predict(lm(Pot ~ Temp, dados), newdata = data.frame(Temp = 0:140), interval = "confidence", level = 0.95) %>%
  as.data.frame()

pred = predict(lm(Pot ~ Temp, dados), newdata = data.frame(Temp = 0:140), interval = "predict", level = 0.95) %>%
  as.data.frame()
```


```{r}
ggplot() + 
  geom_line(data = conf, aes(x = 0:140, y = lwr), col = "green", size = 1) + 
  geom_line(data = conf, aes(x = 0:140, y = upr), col = "green", size = 1) +
  geom_line(data = pred, aes(x = 0:140, y = lwr), col = "red", size = 1) +
  geom_line(data = pred, aes(x = 0:140, y = upr), col = "red", size = 1) + 
  geom_hline(yintercept = 0, col = "darkgray") +
  labs(
    title = "Intervalos de confiança e de predição",
    x = "temperatura",
    y = "potência"
  ) + 
  scale_x_continuous(breaks = seq(0, 200, 20)) +
  theme(text = element_text(size = 16))
```


No gráfico acima, mostramos o intervalo de confiança (em verde) e o intervalo de predição (em vermelho). De cara, já vemos graficamente a maior amplitude do intervalo de predição relativamente ao intervalo de confiança, o que confirma o que já sabemos que é um resultado geral.

Vemos também que, de acordo com o limite inferior do intervalo de confiança, a potência média já poderia ser considerada nula quando a temperatura é cerca de 112.

Para comparar este com o resultado dado no problema 3, em que vimos que a potência média será nula na temperatura de 132,45, temos que lembrar aquele era um resultado pontual. Aqui, estamos considerando o intervalo de confiança, que envolve o valor pontual mais ou menos uma amplitude.


## Problema 35

Nesse caso, como não temos o dataset, não podemos usar a função `lm()` para fazer o ajuste do modelo. Em vez disso, vamos calcular as estimativas dos parâmetros "manualmente", como no exemplo 16.1:

(a)

```{r}
n = 102
sum_xi = 510
sum_yi = 7140
sum_xi2 = 4150
sum_xiyi = 54900
sum_yi2 = 740200
xbar = 5
ybar = 70

beta_hat = (sum_xiyi - n*xbar*ybar)/(sum_xi2 - n*xbar^2)
alpha_hat = ybar - beta_hat*xbar

alpha_hat
beta_hat
```
Logo, nosso modelo ajustado pode ser escrito como

$$ \hat{y}_i = 10 + 12x_i $$

(b) O valor de $\hat{\alpha}$ representa o valor de $\hat{y}$ quando $x = 0$, ou seja, a despesa estimada com viagem para viagens com duração zero é igual a 10 unidades. Já $\hat{\beta}$ significa a variação no custo médio médio da viagem quando incrementamos sua duração em 1 dia. Ou seja, se aumentamos em 1 dia a duração da viagem, aumentamos seu custo médio em 12 unidades.


(c) Para responder a essa pergunta, temos que pensar em termos do intervalo de predição, já que estamos interessados em uma previsão pontual do gasto com a viagem, e não no gasto médio.

Se a probabilidade de faltar dinheiro é de 10%, então estamos falando de um intervalo de predição com coeficiente de confiança igual a 80%. Dessa forma, o que precisamos fazer é calcular um intervalo de predição para $Y(x = 7)$, com $\gamma = 0,80$. Como não temos aqui a saída da função `lm()`, vamos ter que fazer "manualmente". Para tanto, precisamos usar os resultados do problema 29 para calcular a estimativa da variância dos resíduos $S_e^2$:


$$s_y^2 = \frac{SQTot}{n-1} \Rightarrow SQTot = (n-1)*s_y^2 $$


$$ \hat{\beta}^2 = \dfrac{SQReg}{(n-1) s_x^2} \Rightarrow SQReg = (n-1)s_x^2\hat{\beta^2}$$

$$ SQRes = SQTot - SQReg $$
$$ S_e = \dfrac{SQRes}{n-p} = \dfrac{SQRes}{n-2} $$

```{r}
sx = sqrt(sum_xi2/n - xbar^2)
sy = sqrt(sum_yi2/n - ybar^2)
SQReg = (n-1)*sx^2*beta_hat^2
SQTot = (n-1)*sy^2
SQRes = SQTot - SQReg
se = sqrt(SQRes/(n-2))
yhat = 10 + 12*7 #Despesa média estimada para x = 7
IP = yhat + c(-1, 1)*qt(0.9, n-2)*se*sqrt(1 + 1/n + (7-xbar)^2/(sum_xi2-2*xbar*sum_xi+n*xbar^2))

IP
```


Assim, podemos interpretar esse resultado da seguinte forma: Se repetirmos esse mesmo procedimento amostral um número grande de vezes, com o mesmo n, cerca de 20% dos intervalos de predição assim construídos não conterão o verdadeiro valor da despesa com a viagem de 7 dias. Consequentemente, em cerca de 10% dos previsões, a despesa estará acima de 106,92 unidades. Dessa forma, o número procurado é 106,92.



[^bussab_morettin]: MORETTIN, Pedro Alberto; BUSSAB, Wilton Oliveira. **Estatística básica**. Saraiva Educação SA, 2017.